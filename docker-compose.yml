# =====================================================
# DOCKER COMPOSE - Local Development Infrastructure
# =====================================================
#
# This file defines all the services our application needs:
# - PostgreSQL (database)
# - Redis (caching & rate limiting)
# - Kafka + Zookeeper (message queue)
#
# To start all services: docker-compose up -d
# To stop all services:  docker-compose down
# To see logs:           docker-compose logs -f
#

version: '3.8'

services:
  
  # ==================== PostgreSQL Database ====================
  # 
  # PostgreSQL is our main database where we store:
  # - Users
  # - Notifications
  # - Templates
  # - User Preferences

  postgres:
    image: postgres:15                    # Official PostgreSQL image, version 15
    container_name: notification-postgres # Name for easy identification
    environment:
      POSTGRES_DB: notification_db        # Database name (created automatically)
      POSTGRES_USER: postgres             # Database username
      POSTGRES_PASSWORD: postgres         # Database password (use secrets in production!)
    ports:
      - "5432:5432"                        # Host:Container port mapping
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Persist data between restarts
    healthcheck:
      # Check if database is ready to accept connections
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
  
  # ==================== Redis Cache ====================
  #
  # Redis is an in-memory data store. We use it for:
  # 1. Rate Limiting - Track how many notifications per user
  # 2. Caching - Store frequently accessed data (templates, preferences)
  #
  # Why Redis?
  # - Super fast (data is in memory, not on disk)
  # - Simple key-value operations
  # - Built-in expiration (TTL) for rate limit windows
  #
  redis:
    image: redis:7-alpine                 # Alpine = smaller image size
    container_name: notification-redis
    ports:
      - "6379:6379"                        # Default Redis port
    command: redis-server --appendonly yes # Enable persistence
    volumes:
      - redis_data:/data                   # Persist data between restarts
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
  
  # ==================== Zookeeper (Required for Kafka) ====================
  #
  # Zookeeper is a coordination service that Kafka needs to:
  # - Track which brokers are alive
  # - Manage topic configurations
  # - Handle leader election
  #
  # You don't interact with Zookeeper directly, Kafka does.
  #
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: notification-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181         # Port for Kafka to connect
      ZOOKEEPER_TICK_TIME: 2000           # Heartbeat interval in ms
    ports:
      - "2181:2181"
  
  # ==================== Kafka Message Queue ====================
  #
  # Kafka is our message queue. We use it to:
  # 1. Decouple API from notification sending (async processing)
  # 2. Handle traffic spikes (queue absorbs load)
  # 3. Enable retries for failed notifications
  #
  # How it works:
  # - Producer: Our API sends notification messages to Kafka
  # - Consumer: Worker service reads messages and sends notifications
  # - Topic: Like a "folder" for related messages (e.g., "notifications")
  #
  kafka-1:
    image: confluentinc/cp-kafka:7.4.0
    container_name: notification-kafka-1
    depends_on:
      - zookeeper                          # Kafka needs Zookeeper to be running
    ports:
      - "9092:9092"                         # Port for our application to connect
    environment:
      KAFKA_BROKER_ID: 1                    # Unique ID for this Kafka broker
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  # How to find Zookeeper

      # Listeners: How Kafka advertises itself to clients
      # PLAINTEXT = no encryption (fine for local development)
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # Topic settings - now with replication
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3    # 3 brokers, so replication = 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      # Auto-create topics when producer sends to non-existent topic
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-2:
    image: confluentinc/cp-kafka:7.4.0
    container_name: notification-kafka-2
    depends_on:
      - zookeeper
      - kafka-1                              # Ensure kafka-1 starts first
    ports:
      - "9093:9093"                         # Different port for broker 2
    environment:
      KAFKA_BROKER_ID: 2                    # Unique ID for broker 2
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:29093,PLAINTEXT_HOST://localhost:9093
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9093", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  kafka-3:
    image: confluentinc/cp-kafka:7.4.0
    container_name: notification-kafka-3
    depends_on:
      - zookeeper
      - kafka-1
      - kafka-2                              # Ensure previous brokers start first
    ports:
      - "9094:9094"                         # Different port for broker 3
    environment:
      KAFKA_BROKER_ID: 3                    # Unique ID for broker 3
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:29094,PLAINTEXT_HOST://localhost:9094
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9094", "--list"]
      interval: 30s
      timeout: 10s
      retries: 5

  # ==================== Kafka UI (Optional but helpful!) ====================
  #
  # A web interface to view Kafka topics, messages, and consumers.
  # Access at: http://localhost:8090
  #
  # Very useful for debugging!
  #
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: notification-kafka-ui
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "8090:8080"                        # Access UI at localhost:8090
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:29092,kafka-2:29093,kafka-3:29094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  # ==================== Prometheus ====================
  #
  # Metrics collection and time-series storage.
  # Access at: http://localhost:9090
  #
  prometheus:
    image: prom/prometheus:latest
    container_name: notification-prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
    command:
      - "--config.file=/etc/prometheus/prometheus.yml"
      - "--storage.tsdb.retention.time=7d"
    depends_on:
      - postgres-exporter
      - redis-exporter
      - kafka-exporter

  # ==================== Grafana ====================
  #
  # Dashboard UI for visualizing metrics and stress spikes.
  # Access at: http://localhost:3000 (admin/admin)
  #
  grafana:
    image: grafana/grafana:latest
    container_name: notification-grafana
    ports:
      - "3000:3000"
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
      GF_USERS_ALLOW_SIGN_UP: "false"
    volumes:
      - ./monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus

  # ==================== PostgreSQL Exporter ====================
  #
  # Exposes PostgreSQL metrics to Prometheus.
  #
  postgres-exporter:
    image: prometheuscommunity/postgres-exporter:latest
    container_name: notification-postgres-exporter
    environment:
      DATA_SOURCE_NAME: postgresql://postgres:postgres@postgres:5432/notification_db?sslmode=disable
    ports:
      - "9187:9187"
    depends_on:
      - postgres

  # ==================== Redis Exporter ====================
  #
  # Exposes Redis metrics to Prometheus.
  #
  redis-exporter:
    image: oliver006/redis_exporter:latest
    container_name: notification-redis-exporter
    environment:
      REDIS_ADDR: redis://redis:6379
    ports:
      - "9121:9121"
    depends_on:
      - redis

  # ==================== Kafka Exporter ====================
  #
  # Exposes Kafka cluster/topic/consumer metrics to Prometheus.
  #
  kafka-exporter:
    image: danielqsj/kafka-exporter:latest
    container_name: notification-kafka-exporter
    command:
      - "--kafka.server=kafka-1:29092"
      - "--kafka.server=kafka-2:29093"
      - "--kafka.server=kafka-3:29094"
    ports:
      - "9308:9308"
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3

# ==================== Volumes ====================
#
# Volumes persist data outside the container.
# Without volumes, data is lost when containers restart.
#
volumes:
  postgres_data:    # PostgreSQL data files
  redis_data:       # Redis persistence files
  grafana_data:     # Grafana data (dashboards, preferences)
